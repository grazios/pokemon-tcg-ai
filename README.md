# 🃏 Pokemon TCG AI

ポケモンカードゲーム（本家TCG）の対戦解析AI。将棋AIの評価値バーのように、対戦中の勝率・最善手をリアルタイム表示する。

## 🎯 ビジョン

ポケカ対戦動画を見ながら：
- **勝率バー**がリアルタイムで動く
- **最善手**を提案（「ここはボスの指令を使うべき」）
- **プレイミス検出**（「この手で勝率が20%下がった」）
- **LLMによる自然言語解説**（「なぜこの手がいいか」）

## 🏗️ アーキテクチャ

```
┌─────────────────────────────────────────┐
│           動画解析 / UI レイヤー          │
│   (カード認識 → 盤面状態 → オーバーレイ)   │
├─────────────────────────────────────────┤
│          LLM 解説レイヤー                │
│   (最善手の理由を自然言語で生成)           │
├─────────────────────────────────────────┤
│          強化学習 AI エンジン             │
│   (PPO自己対戦 → 最善手・勝率算出)        │
├─────────────────────────────────────────┤
│          ゲームエンジン / シミュレーター    │
│   (ポケカTCGルール完全実装)              │
├─────────────────────────────────────────┤
│          カードデータベース               │
│   (全カードデータ / JSON)                │
└─────────────────────────────────────────┘
```

## 📦 コンポーネント

| # | コンポーネント | 状態 | 概要 |
|---|-------------|------|------|
| 1 | カードDB | 🟡 Phase1完了 | Hレギュ8種ミニDB（data/cards.json） |
| 2 | ゲームエンジン | 🟡 Phase1完了 | 基本ルール実装済み（engine/） |
| 3 | 強化学習AI | 🟡 Phase1完了 | MaskablePPO vs Random動作確認済み |
| 4 | LLM解説 | 🔴 未着手 | 最善手の理由を自然言語で生成 |
| 5 | 動画解析UI | 🔴 未着手 | カード認識＋勝率オーバーレイ表示 |

## 🔧 開発ルール

### README駆動開発

1. **開発前に必ずこのREADMEを読む**
2. **重要な設計判断・仕様変更はREADMEに追記する**
3. **各コンポーネントの進捗はここで管理する**
4. READMEが古くなったら開発を止めてでも更新する

### レビュー必須

- **実装完了後は必ずレビュア部隊（dev-review-team）を起動する**
- コードレビュー・UXレビュー・QA・実装ギャップ分析・初心者テスト・管理者レビュー・テストレビューの7観点で並列レビュー
- レビュー指摘は修正Sprintで対応してからマージ

### コードルール

- （開発が進んだら追記）

## 📋 開発ログ

### 2026-02-19
- プロジェクト作成 🎉
- ビジョン・アーキテクチャ定義
- **Phase 1 プロトタイプ完成** 🎮
  - カードDB: Hレギュ8種（Pansear, Charcadet, Paldean Tauros, Shellos, Mantine, Magnemite, Blitzle, Marill）
  - ゲームエンジン: デッキ/手札/場/サイド、エネルギー付与、技使用（ダメージ+弱点）、きぜつ、勝利判定
  - Gymnasium環境: MaskablePPO対応、action mask実装
  - PPO学習: 20,000 steps、vs Random 99.5%勝率
  - ミニデッキ20枚（ポケモン16枚+エネルギー12枚、サイド4枚）

#### Phase 1 設計判断
- デッキサイズ20枚（標準60枚→ミニ版で高速シミュレーション）
- サイド4枚（標準6枚→ミニ版対応）
- トレーナーズ/特性はスキップ（Phase 2で追加予定）
- 先攻有利（P0勝率~60% in smart random vs smart random）はTCG通りの仕様
- 対戦相手はランダムポリシー（自己対戦はPhase 2）

## 🔗 参考

- [sethkarten/tcg](https://github.com/sethkarten/tcg) — ポケポケ(Pocket)用だがアーキテクチャ参考（C+Python, PPO, Gymnasium）
- [AngelFireLA](https://github.com/AngelFireLA) — Python製シミュレーター（読みやすい、改造向き）

## 📝 決定事項

- 本家ポケカTCG対応（ポケポケではない）
- 強化学習（A）+ LLM解説（C）のハイブリッド
- 将棋解析AI的なUXを目指す

---

**© 2026 grazios**
